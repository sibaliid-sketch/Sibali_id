name: Backup Automation

on:
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup PHP
      uses: shivammathur/setup-php@v2
      with:
        php-version: 8.2
        extensions: pdo, pdo_mysql, mbstring, intl, zip, bcmath
        tools: composer:v2

    - name: Install PHP dependencies
      run: composer install --no-progress --prefer-dist --optimize-autoloader --no-dev

    - name: Generate SSH key for backup server
      run: |
        mkdir -p ~/.ssh
        echo "${{ secrets.BACKUP_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        ssh-keyscan -H ${{ secrets.BACKUP_HOST }} >> ~/.ssh/known_hosts

    - name: Run database backup
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          cd /opt/backup-scripts
          ./backup-database.sh sibali-production
        EOF

    - name: Run storage backup
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          cd /opt/backup-scripts
          ./backup-storage.sh sibali-production
        EOF

    - name: Encrypt backup files
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          cd /opt/backups
          # Encrypt database backup
          gpg --encrypt --recipient ${{ secrets.GPG_RECIPIENT }} --output sibali-db-$(date +%Y%m%d).sql.gz.enc sibali-db-$(date +%Y%m%d).sql.gz
          # Encrypt storage backup
          gpg --encrypt --recipient ${{ secrets.GPG_RECIPIENT }} --output sibali-storage-$(date +%Y%m%d).tar.gz.enc sibali-storage-$(date +%Y%m%d).tar.gz
        EOF

    - name: Upload encrypted backups to S3
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          # Install AWS CLI if not present
          if ! command -v aws &> /dev/null; then
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
          fi

          # Configure AWS CLI
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws configure set default.region ${{ secrets.AWS_REGION }}

          # Upload backups to S3
          aws s3 cp /opt/backups/sibali-db-$(date +%Y%m%d).sql.gz.enc s3://${{ secrets.S3_BACKUP_BUCKET }}/database/ --storage-class STANDARD_IA
          aws s3 cp /opt/backups/sibali-storage-$(date +%Y%m%d).tar.gz.enc s3://${{ secrets.S3_BACKUP_BUCKET }}/storage/ --storage-class STANDARD_IA
        EOF

    - name: Verify backup integrity
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          # Verify checksums
          cd /opt/backups
          sha256sum sibali-db-$(date +%Y%m%d).sql.gz.enc > db-checksum.txt
          sha256sum sibali-storage-$(date +%Y%m%d).tar.gz.enc > storage-checksum.txt

          # Upload checksums to S3
          aws s3 cp db-checksum.txt s3://${{ secrets.S3_BACKUP_BUCKET }}/checksums/
          aws s3 cp storage-checksum.txt s3://${{ secrets.S3_BACKUP_BUCKET }}/checksums/
        EOF

    - name: Rotate old backups
      run: |
        ssh -o StrictHostKeyChecking=no ${{ secrets.BACKUP_USER }}@${{ secrets.BACKUP_HOST }} << EOF
          # Remove backups older than 30 days
          find /opt/backups -name "*.enc" -mtime +30 -delete
          find /opt/backups -name "*.gz" -mtime +30 -delete

          # Remove old S3 objects
          aws s3api list-objects-v2 --bucket ${{ secrets.S3_BACKUP_BUCKET }} --prefix database/ --query 'Contents[?LastModified<`'"$(date -d '30 days ago' +%Y-%m-%d)"'`].Key' --output text | xargs -I {} aws s3 rm s3://${{ secrets.S3_BACKUP_BUCKET }}/{}
          aws s3api list-objects-v2 --bucket ${{ secrets.S3_BACKUP_BUCKET }} --prefix storage/ --query 'Contents[?LastModified<`'"$(date -d '30 days ago' +%Y-%m-%d)"'`].Key' --output text | xargs -I {} aws s3 rm s3://${{ secrets.S3_BACKUP_BUCKET }}/{}
        EOF

    - name: Send backup notification
      if: always()
      run: |
        curl -X POST -H 'Content-type: application/json' --data '{"text":"Backup completed for Sibali.id - Status: '"${{ job.status }}"'"}' ${{ secrets.SLACK_WEBHOOK_URL }}
